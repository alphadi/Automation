{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alphadi/Automation/blob/main/av_LLM_personalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e4T7xQeDQz8",
        "outputId": "d822104e-d956-44c6-ea86-d0994f07e082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ShopifyAPI (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyactiveresource (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain-core 0.3.25 requires langsmith<0.3,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\n",
            "langchain-core 0.3.25 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n",
            "wandb 0.19.1 requires pydantic<3,>=2.6, but you have pydantic 1.10.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "  python-dotenv==1.0.0 \\\n",
        "  langchain==0.0.313 \\\n",
        "  tiktoken==0.5.1 \\\n",
        "  openai==0.28.1 \\\n",
        "  klaviyo-api==5.2.0 \\\n",
        "  ShopifyAPI==12.3.0 \\\n",
        "  redis==5.0.1 \\\n",
        "  pandas-gbq==0.19.2 \\\n",
        "  Faker==19.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "v5ulxlWnDglG",
        "outputId": "6fe7e30b-9cd1-4a7d-d0c1-8f93ad7aa51c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "lsJ2oREQwCTV",
        "outputId": "5a8e3260-fb73-497c-a387-1a9b30a810d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Specify the path to your .env file if it's not in the current directory\n",
        "dotenv_path = \".env\"  # Replace with the actual path if needed\n",
        "success = load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "if success:\n",
        "    print(\"Environment variables loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load .env file.\")\n"
      ],
      "metadata": {
        "id": "zY9lrRqgvvH9",
        "outputId": "934971a0-348a-43b2-873f-077fe8948d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load .env file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "aiWpqJmgsfNu",
        "outputId": "745714ba-746b-470d-f2b7-2f5c8123949c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if os.path.exists(\".env\"):\n",
        "  print(\".env file exists\")\n",
        "else:\n",
        "  print(\".env file not found\")"
      ],
      "metadata": {
        "id": "bs88FdHAsk6F",
        "outputId": "1f9202e2-0d11-4ae4-9ca0-d5e5e48f79f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".env file not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Redis database (redis.com) with redis-py\n",
        "\n",
        "import redis\n",
        "from langchain.vectorstores.redis import Redis\n",
        "\n",
        "url=os.getenv('REDIS_URL')\n",
        "\n",
        "host=os.getenv('REDIS_HOST')\n",
        "password=os.getenv('REDIS_PASSWORD')\n",
        "port=int(os.getenv('REDIS_PORT'))\n",
        "\n",
        "\n",
        "r = redis.Redis(\n",
        "  host=host,\n",
        "  port=port,\n",
        "  password=password)"
      ],
      "metadata": {
        "id": "M8X8h0iHDlE5",
        "outputId": "3470ae92-2f82-4d9a-8c7d-029226333b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-32a6bc4fc307>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REDIS_HOST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REDIS_PASSWORD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REDIS_PORT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check redis connection\n",
        "\n",
        "r.ping()\n",
        "\n"
      ],
      "metadata": {
        "id": "fDOpsq-3DoYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if anything is stored in the database, flush if needed\n",
        "\n",
        "r.keys()\n",
        "#r.flushdb() # in case you need to delete the data again"
      ],
      "metadata": {
        "id": "CPhrtcmNDt37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shopify Product Data to Redis: Building The Retriever"
      ],
      "metadata": {
        "id": "pLizBM-ND3d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic functions used for extracting data from Shopify REST API\n",
        "\n",
        "import os\n",
        "import shopify\n",
        "import pandas as pd\n",
        "\n",
        "token = os.getenv('SHOPIFY_TOKEN')\n",
        "merchant= os.getenv('SHOPIFY_MERCHANT')\n",
        "\n",
        "api_session = shopify.Session(merchant,'2023-04', token)\n",
        "shopify.ShopifyResource.activate_session(api_session)\n",
        "\n",
        "def get_data(object_name):\n",
        "    all_data=[]\n",
        "    attribute=getattr(shopify,object_name)\n",
        "    data=attribute.find(since_id=0, limit=250)\n",
        "    for d in data:\n",
        "        all_data.append(d)\n",
        "    while data.has_next_page():\n",
        "        data=data.next_page()\n",
        "        for d in data:\n",
        "            all_data.append(d)\n",
        "    return all_data\n",
        "\n",
        "def product_frame(products):\n",
        "    all_products=[]\n",
        "    for product in products:\n",
        "        p=product.attributes\n",
        "        record={k: p.get(k, None) for k in ('id', 'title','vendor','body_html','handle','status','tags')}\n",
        "        record['price']=p['variants'][0].attributes['price']\n",
        "        all_products.append(record)\n",
        "    df=pd.DataFrame(all_products)\n",
        "    return df"
      ],
      "metadata": {
        "id": "bqoWI2uQDy9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract product data from Shopify (or json file) and transform into a suitable format for vector storage.\n",
        "# A sample of Shopify products can be found on https://github.com/rabbitmetrics/personalize-LLMs\n",
        "\n",
        "products=get_data('Product')\n",
        "frame=product_frame(products)\n",
        "\n",
        "#frame.reset_index(drop=True).to_json('products.json',orient='records')\n",
        "#frame=pd.read_json('products.json')\n",
        "\n",
        "\n",
        "max_text_length=800\n",
        "def truncate_text(text):\n",
        "    return text[:max_text_length]\n",
        "frame['body_html']=frame.apply(lambda row: truncate_text(row['body_html']),axis=1)\n",
        "\n",
        "product_data=frame.reset_index(drop=True).to_dict(orient='index')\n",
        "\n",
        "texts = [\n",
        "    v['title'] for k, v in product_data.items()\n",
        "]\n",
        "\n",
        "metadatas = list(product_data.values())"
      ],
      "metadata": {
        "id": "COmfH4CtD9tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI embeddings, you can also use HuggingFace embeddings by pip installing SentenceTransformers\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "RSR9Vu41EFTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Redis and load vector data from LangChain\n",
        "\n",
        "from langchain.vectorstores.redis import Redis\n",
        "\n",
        "vector_schema = {\"algorithm\": \"HNSW\",\"initial_cap\": 400}\n",
        "\n",
        "rds = Redis.from_texts(\n",
        "    texts,\n",
        "    embeddings,\n",
        "    metadatas=metadatas,\n",
        "    redis_url=url,\n",
        "    index_name=\"shopify_products\",\n",
        "    vector_schema=vector_schema,\n",
        "\n",
        ")\n",
        "\n",
        "# check that vector data has been added\n",
        "r.keys()"
      ],
      "metadata": {
        "id": "DUzgP5HcEH6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To delete the products from the database run\n",
        "#for key in r.scan_iter(\"doc:shopify_products:*\"):\n",
        "#  r.delete(key)"
      ],
      "metadata": {
        "id": "nj9uCaPuER7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that we can do VSS\n",
        "docs=rds.similarity_search(\"Adidas shoes\", 5)\n",
        "docs"
      ],
      "metadata": {
        "id": "OKSa7-szEAfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the schema to a yaml file and use it to connect the existing index from another instance\n",
        "\n",
        "rds.write_schema(\"redis_schema.yaml\")"
      ],
      "metadata": {
        "id": "ziGiqevAEfr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Personalization Data to BigQuery"
      ],
      "metadata": {
        "id": "dq99JWIpEnD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "import pandas_gbq"
      ],
      "metadata": {
        "id": "6BbD44PzEjrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incentives = ['bogo','free_shipping','special_offer','free_gift','10% discount','no_incentive']\n",
        "\n",
        "faker = Faker()\n",
        "domain='your_domain' # you can just add some id instead that can be used as a primary key\n",
        "\n",
        "def customer_frame():\n",
        "    ict=[random.choice(incentives) for i in range(100)]\n",
        "    df=pd.DataFrame(ict,columns=['incentive'])\n",
        "    df['feature_timestamp']=df.apply(lambda row: datetime.datetime.now()-datetime.timedelta(hours=2), axis=1)\n",
        "    df['created']=df.apply(lambda row: datetime.datetime.now()-datetime.timedelta(hours=2),axis=1)\n",
        "    df['first_name']=df.apply(lambda row: faker.first_name(), axis=1)\n",
        "    df['last_name']=df.apply(lambda row: faker.last_name(), axis=1)\n",
        "    df['email']=df.apply(lambda row:\n",
        "                     row['first_name'].lower()+row['last_name'].lower()+domain,\n",
        "                     axis=1)\n",
        "    df = df[['email', 'first_name', 'last_name', 'incentive', 'created','feature_timestamp']]\n",
        "    return df\n",
        "\n",
        "feature_frame=customer_frame()"
      ],
      "metadata": {
        "id": "aTvKAxQCEsns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_id='table_name.dataset_name'\n",
        "project_id=\"your_gcp_project\"\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    'service_account_json_key',\n",
        ")\n",
        "\n",
        "pandas_gbq.context.credentials = credentials\n",
        "pandas_gbq.context.project = project_id\n",
        "\n",
        "pandas_gbq.to_gbq(feature_frame, table_id, project_id=project_id)"
      ],
      "metadata": {
        "id": "JbOL7uPWEvLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Feast with BigQuery and Redis"
      ],
      "metadata": {
        "id": "id-4Hr8lFaOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Feast. We'll be using BigQuery as offline store and Redis as online store\n",
        "\n",
        "! pip install -qU 'feast[gcp, redis]'"
      ],
      "metadata": {
        "id": "O-_m55WHFXfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature repo allowing us to connect to GCP - choose some appropriate name\n",
        "\n",
        "! feast init langchain_klaviyo -t gcp"
      ],
      "metadata": {
        "id": "yD63DNENVTER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change dir to where the feature_store.yaml file is located\n",
        "# Configure the yaml file and the example_repo.py file. Example setup of these files are found on https://github.com/rabbitmetrics/personalize-LLMs\n",
        "\n",
        "%cd langchain_klaviyo/feature_repo/"
      ],
      "metadata": {
        "id": "By-uQBVEFf2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set application credentials using the json key created on GCP. Move or copy the json key to the current folder first.\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./klaviyo.json\""
      ],
      "metadata": {
        "id": "76GX1bbMFnbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply configuations\n",
        "\n",
        "! feast apply"
      ],
      "metadata": {
        "id": "XRck2QMvFtlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Materialize features (changes) from offline store to online store\n",
        "\n",
        "!feast materialize-incremental $(date -u +\"%Y-%m-%dT%H:%M:%S\")"
      ],
      "metadata": {
        "id": "Vb2wjGKfGGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that features have been materialized to Redis\n",
        "\n",
        "r.keys()"
      ],
      "metadata": {
        "id": "1Slcp26oJnQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import FeatureStore that allows us to extract the features\n",
        "\n",
        "from feast import FeatureStore\n",
        "\n",
        "\n",
        "feast_repo_path = \"./\"\n",
        "store = FeatureStore(repo_path=feast_repo_path)"
      ],
      "metadata": {
        "id": "HV1z3mJ5Jp2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function that extracts features for a particular customer\n",
        "\n",
        "def get_feature(email):\n",
        "    f=store.get_online_features(\n",
        "        features=[\n",
        "        \"incentives:incentive\",\n",
        "        \"incentives:first_name\",\n",
        "        \"incentives:last_name\",\n",
        "    ],\n",
        "        entity_rows=[{\"email\": email}]\n",
        "    ).to_dict()\n",
        "    return f"
      ],
      "metadata": {
        "id": "csRkJgAMJ4xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feature()"
      ],
      "metadata": {
        "id": "XnB0g9w7J5RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Injecting Features into LangChain Prompt Templates"
      ],
      "metadata": {
        "id": "sQGUGvE9KItH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate, StringPromptTemplate\n",
        "\n",
        "\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "ffH3TW_0KHD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model_name=\"gpt-4\", temperature=0.2)"
      ],
      "metadata": {
        "id": "Ol12rl8BKOA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entire Email template\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are an email writing assistant that wants to convert customers based on the information given.\n",
        "Take the customer data into account when formulating an email.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "Use the recommended incentive to craft an offer but don't mention the incentive explicitly in the email.\n",
        "\n",
        "Relevant products: {text}\n",
        "\n",
        "Email is from team Running Customer\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "e-vNIt74KQcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you only need a few lines to load to Klaviyo\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are an email writing assistant that wants to convert customers based on the information given.\n",
        "\n",
        "Write 3 sentences that can be used in a marketing email targeting the specific customer. Take the recommended\n",
        "incentive given in the \"customer data\" section into account when formulating the paragraph.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "Use the recommended incentive to craft an offer but don't mention the incentive explicitly in the email.\n",
        "\n",
        "Relevant products: {text}\n",
        "\n",
        "No need for signature as this will be pasted into an email template\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "XnUrqkxAKSeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create customized prompt template with feature data\n",
        "\n",
        "class FeastPromptTemplate(StringPromptTemplate):\n",
        "    def format(self, **kwargs) -> str:\n",
        "        email = kwargs.pop(\"email\")\n",
        "        feature_vector = store.get_online_features(\n",
        "            features=[\n",
        "                \"incentives:incentive\",\n",
        "                \"incentives:first_name\",\n",
        "                \"incentives:last_name\",\n",
        "            ],\n",
        "            entity_rows=[{\"email\": email}],\n",
        "        ).to_dict()\n",
        "        kwargs[\"incentive\"] = feature_vector[\"incentive\"][0]\n",
        "        return base_prompt.format(**kwargs)"
      ],
      "metadata": {
        "id": "pn9chHffKU_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_prompt_template = FeastPromptTemplate(input_variables=[\"email\",\"text\"])"
      ],
      "metadata": {
        "id": "g_zAJQzlKXjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_prompt_template.format(email=\"davidhill@mg.rabbitpromotion.com\",text=\"adidas shoes\"))"
      ],
      "metadata": {
        "id": "z70nci0WKFpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summarize chain with GPT-4 and customized feature prompt template\n",
        "\n",
        "chain = load_summarize_chain(chat, chain_type=\"stuff\", prompt=feature_prompt_template)\n",
        "response=chain({\"input_documents\": docs,\"email\": \"some_email\"},return_only_outputs=False)\n",
        "\n",
        "print(response['output_text'])"
      ],
      "metadata": {
        "id": "LPRNzqaaJ-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot\n",
        "We can use the same feast+redis backend to feed a chatbot with customer features. This allows for personalization of all interactions with customers. If the pipeline to Redis through Feast is set up to be event-driven this allows for real-time contextualization."
      ],
      "metadata": {
        "id": "1sX6QU0qKhrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create template that allows for both feature injection and customer interaction\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are a conversational ecommerce shopping assistant that wants to convert the customer based on\n",
        "the information given.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "\n",
        "Human: {question}\n",
        "\n",
        "Relevant products: {context}\n",
        "\n",
        "\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "gAK4DA7SKi3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Template used for condensing the question and chat history\n",
        "\n",
        "template=\"\"\"\n",
        "Use the follow up input {question}, and the chat history {chat_history} to formulate a standalone question.\n",
        "\"\"\"\n",
        "condense_question_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "YU35poTbKtcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use ConversationalRetrievalChain with streaming output for the chatbot\n",
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.callbacks.manager import AsyncCallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "id": "zhdgLPnJKv5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_prompt_template = FeastPromptTemplate(input_variables=[\"email\",\"question\",\"context\"])"
      ],
      "metadata": {
        "id": "lCy3wO74Kyc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the chatbot using ConversationalRetrievalChain - note that the feature prompt template is passed as kwargs.\n",
        "\n",
        "chatbot = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(temperature=0,\n",
        "               model=\"gpt-4\",\n",
        "               streaming=True,\n",
        "               callbacks=AsyncCallbackManager([\n",
        "               StreamingStdOutCallbackHandler()\n",
        "    ]),\n",
        "              ),\n",
        "    rds.as_retriever(),\n",
        "    condense_question_prompt = condense_question_prompt,\n",
        "    condense_question_llm = ChatOpenAI(temperature=0, model='gpt-4'),\n",
        "    combine_docs_chain_kwargs=dict(prompt=feature_prompt_template),\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "-bOMQDzTK0kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_prompt_template.format(email=\"some_email\",question=\"looking for shoes\",context=\"adidas\"))"
      ],
      "metadata": {
        "id": "iYbQ4W83K2wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"I'm looking for somme cool kids sneakers\"\n",
        "result = chatbot({\"question\": query,\"email\":\"some_email\", \"chat_history\": chat_history})"
      ],
      "metadata": {
        "id": "llUGv7cFK5Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ANBTVUfK7m1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}